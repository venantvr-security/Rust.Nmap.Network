# =============================================================================
# KIBANA LAB - ELK Stack pour visualisation centralis√©e des IDS
# =============================================================================
#
# ARCHITECTURE (Mermaid):
# ```mermaid
# graph TB
#     subgraph HOST["üñ•Ô∏è Host Network (network_mode: host)"]
#         KB["üìä kibana<br/>localhost:5601"]
#         FB["üì® filebeat"]
#     end
#
#     subgraph kibana_net["kibana_net"]
#         ES["üîç elasticsearch<br/>:9200 (port mapping)"]
#     end
#
#     subgraph IDS_LOGS["üìÅ Sources de logs IDS"]
#         SNORT["snort-lab/logs/<br/>alert_fast.log"]
#         SURI["suricata-lab/logs/<br/>eve.json"]
#         ZEEK["zeek-lab/logs/<br/>conn.log, http.log..."]
#     end
#
#     FB -->|lecture| SNORT
#     FB -->|lecture| SURI
#     FB -->|lecture| ZEEK
#     FB -->|envoi localhost:9200| ES
#     KB -->|requ√™tes localhost:9200| ES
# ```
#
# NOTE: Kibana et Filebeat utilisent network_mode: host pour contourner
# les probl√®mes de connectivit√© inter-conteneurs Docker (IPv6/IPv4).
#
# POURQUOI ELK STACK?
# - Elasticsearch: Moteur de recherche et analytics distribu√©
# - Kibana: Visualisation interactive des donn√©es
# - Filebeat: Agent l√©ger de collecte de logs
#
# CHOIX STRAT√âGIQUES:
# - S√©curit√© d√©sactiv√©e: Environnement lab, pas de mot de passe
# - Indices s√©par√©s: Un index par IDS (snort-*, suricata-*, zeek-*)
# - 3 dashboards: Visualisation d√©di√©e pour chaque IDS
# - Volumes mont√©s en lecture seule: Pas de modification des logs originaux
#
# PORTS EXPOS√âS:
# - 5601: Kibana dashboard (http://localhost:5601)
# - 9200: Elasticsearch API (http://localhost:9200)
#
# COMMANDES UTILES:
# - D√©marrer: docker compose up -d
# - Logs Filebeat: docker logs -f kibana_filebeat
# - Status ES: curl http://localhost:9200/_cluster/health?pretty
# - Indices: curl http://localhost:9200/_cat/indices?v
# =============================================================================

networks:
  kibana_net:
    driver: bridge
    ipam:
      config:
        - subnet: 172.31.0.0/24  # Sous-r√©seau d√©di√© au lab Kibana

services:
  # ---------------------------------------------------------------------------
  # ELASTICSEARCH - Moteur de recherche et stockage
  # ---------------------------------------------------------------------------
  # Elasticsearch stocke tous les logs des IDS dans des indices s√©par√©s
  # et permet des recherches rapides et des agr√©gations pour les dashboards
  #
  # CONFIGURATION S√âCURIT√â:
  # - xpack.security.enabled=false: Pas d'authentification (lab uniquement!)
  # - discovery.type=single-node: Mode standalone, pas de cluster
  #
  # M√âMOIRE:
  # - ES_JAVA_OPTS=-Xms512m -Xmx512m: Limite la heap JVM √† 512MB
  # - Suffisant pour un lab, augmenter en production
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.17.18
    container_name: kibana_elasticsearch
    networks:
      - kibana_net
    environment:
      # Mode single-node (pas de d√©couverte de cluster)
      - discovery.type=single-node
      # D√©sactiver la s√©curit√© pour simplifier l'acc√®s lab
      - xpack.security.enabled=false
      - xpack.security.http.ssl.enabled=false
      - xpack.security.transport.ssl.enabled=false
      # Limiter la m√©moire JVM pour environnement lab
      - ES_JAVA_OPTS=-Xms512m -Xmx512m
      # Nom du cluster
      - cluster.name=ids-lab
      # Permettre les requ√™tes CORS (pour debug)
      - http.cors.enabled=true
      - http.cors.allow-origin="*"
    volumes:
      # Donn√©es persistantes (indices, shards)
      - es_data:/usr/share/elasticsearch/data
    ports:
      # API REST Elasticsearch
      - "9200:9200"
    # Health check pour que Kibana attende qu'ES soit pr√™t
    # Note: avec network.host=_site_, ES √©coute sur 172.31.0.10, pas localhost
    healthcheck:
      test: ["CMD-SHELL", "curl -s http://localhost:9200/_cluster/health | grep -q 'green\\|yellow'"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    restart: unless-stopped

  # ---------------------------------------------------------------------------
  # KIBANA - Interface de visualisation
  # ---------------------------------------------------------------------------
  # Kibana fournit l'interface web pour visualiser les donn√©es Elasticsearch
  # Accessible sur http://localhost:5601
  #
  # DASHBOARDS √Ä CR√âER (manuellement apr√®s d√©marrage):
  # 1. Suricata Dashboard: Index pattern "suricata-*"
  # 2. Zeek Dashboard: Index pattern "zeek-*"
  # 3. Snort Dashboard: Index pattern "snort-*"
  #
  # ACC√àS SANS AUTHENTIFICATION:
  # - XPACK_SECURITY_ENABLED=false d√©sactive le login
  kibana:
    image: docker.elastic.co/kibana/kibana:7.17.18
    container_name: kibana_dashboard
    # Utiliser le r√©seau host pour √©viter les probl√®mes de connectivit√© Docker
    network_mode: host
    depends_on:
      # Attendre qu'Elasticsearch soit healthy avant de d√©marrer
      elasticsearch:
        condition: service_healthy
    environment:
      # URL d'Elasticsearch (localhost car network_mode: host)
      - ELASTICSEARCH_HOSTS=http://localhost:9200
      # D√©sactiver la s√©curit√© (pas de login)
      - XPACK_SECURITY_ENABLED=false
      # √âcouter sur toutes les interfaces
      - SERVER_HOST=0.0.0.0
      # Nom du serveur
      - SERVER_NAME=ids-lab-kibana
      # Langue fran√ßaise
      - I18N_LOCALE=fr
    # Pas de ports: avec network_mode: host, Kibana √©coute directement sur localhost:5601
    restart: unless-stopped

  # ---------------------------------------------------------------------------
  # FILEBEAT - Collecteur de logs
  # ---------------------------------------------------------------------------
  # Filebeat lit les logs des 3 IDS et les envoie √† Elasticsearch
  # Chaque IDS a sa propre configuration d'input avec parsing adapt√©
  #
  # FORMATS DE LOGS:
  # - Suricata: JSON natif (eve.json) - parsing direct
  # - Zeek: TSV avec headers - parsing par dissect
  # - Snort: Texte alert_fast - parsing par dissect/grok
  #
  # VOLUMES MONT√âS EN LECTURE SEULE:
  # - Les logs originaux ne sont jamais modifi√©s
  # - Filebeat maintient un registre de position dans filebeat_data
  filebeat:
    image: docker.elastic.co/beats/filebeat:7.17.18
    container_name: kibana_filebeat
    # Root n√©cessaire pour lire les fichiers de logs des autres containers
    user: root
    # Utiliser le r√©seau host pour √©viter les probl√®mes de connectivit√© Docker
    network_mode: host
    depends_on:
      # Attendre qu'Elasticsearch soit pr√™t
      elasticsearch:
        condition: service_healthy
    volumes:
      # Configuration Filebeat
      - ./filebeat/filebeat.yml:/usr/share/filebeat/filebeat.yml:ro
      # Monter les r√©pertoires de logs des IDS (lecture seule)
      # Note: Chemins relatifs depuis kibana-lab/
      - ../snort-lab/logs:/var/log/snort:ro
      - ../suricata-lab/logs:/var/log/suricata:ro
      - ../zeek-lab/logs:/var/log/zeek:ro
      # Registre Filebeat (position de lecture persistante)
      - filebeat_data:/usr/share/filebeat/data
    # Lancer Filebeat avec logs verbeux et ignorer les permissions strictes
    command: filebeat -e -strict.perms=false
    restart: unless-stopped

# ---------------------------------------------------------------------------
# VOLUMES PERSISTANTS
# ---------------------------------------------------------------------------
volumes:
  # Donn√©es Elasticsearch (indices, shards, m√©tadonn√©es)
  es_data:
    driver: local
  # Registre Filebeat (positions de lecture des fichiers)
  filebeat_data:
    driver: local
